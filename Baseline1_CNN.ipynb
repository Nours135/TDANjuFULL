{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先从简单的CNN开始写吧，嘶，主要是数据太少了orzzzzz\n",
    "# 所以只能做分类了，完蛋，我开始写之前怎么就没想到这点呢\n",
    "# 没事，3个类，33个数据一类，勉勉强强够了，大不了我自己再洗一年的数据\n",
    "\n",
    "import pandas as pd\n",
    "from utils import randomSplit, Accumulator\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold         # k折交叉验\n",
    "from sklearn.preprocessing import StandardScaler  # 归一化\n",
    "\n",
    "\n",
    "def rank2class(df):\n",
    "    if df['LgRk'] <= 6:\n",
    "        return 0\n",
    "    elif 6 < df['LgRk'] <= 13:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 1, 30, 151])\n"
     ]
    }
   ],
   "source": [
    "class myDataset():\n",
    "    def __init__(self):\n",
    "        self.player = pd.read_csv('DLdata\\outfielder_combined_from_raw_fillna.csv', header=0, encoding='utf-8')\n",
    "        self.player = self.player.drop(['Player', 'Pos', 'Comp', 'Age', 'Born'], axis=1)\n",
    "        scaler = StandardScaler()  # z score 归一化\n",
    "        for col in self.player.columns:\n",
    "            if col in ('Squad', \"Season\"): continue\n",
    "            self.player[[col]] = scaler.fit_transform(self.player[[col]])\n",
    "\n",
    "\n",
    "        self.league = pd.read_excel('DLdata/SquadPerformance2021.xlsx', sheet_name='Sheet1')\n",
    "        self.league['tier'] = self.league.apply(rank2class, axis=1)\n",
    "        self.league = self.league[['Squad', 'Season', 'tier']]  \n",
    "        \n",
    "        #self.size_stat = [] 结果是这个最大的数据集，是30\n",
    "\n",
    "        # 生成连续的变量\n",
    "        self.X = []  # in GNN: list of Data object; in CNN: list of 2-dim tensors; in MLs list of 1-dim tensors\n",
    "        self.y = []\n",
    "        for id in self.league.index:\n",
    "            squad = self.league.at[id, 'Squad']\n",
    "            season = self.league.at[id, 'Season']\n",
    "            if season == 2021: continue  # 发现github的数据在2021年仅仅只有前几场比赛的，所以不得不舍弃了orzzz\n",
    "            self.X.append(self.Squad2Player(squad, season)) \n",
    "            self.y.append(self.league.at[id, 'tier'])  # 作为监督的label\n",
    "        #count = np.array(self.y)\n",
    "        #print((count==0).sum()) 120\n",
    "        #print((count==1).sum()) 140\n",
    "        #print((count==2).sum()) 132\n",
    "\n",
    "\n",
    "    def Squad2Player(self, squad, season):\n",
    "        \"输入squad的名字，输出球队球员的数据\"\n",
    "        season = str(season) + '-' + str(int(season) + 1)\n",
    "        re = self.player[self.player['Squad'] == squad]\n",
    "        #print(re.columns)\n",
    "        re = re[re['Season'] == season].drop(['Squad', 'Season'], axis=1)\n",
    "        re = torch.Tensor(re.values)  # shape [nplayers, features]\n",
    "        # print(re.shape) [20, 151]\n",
    "        #self.size_stat.append(re.shape[0])\n",
    "\n",
    "        upBound = 30\n",
    "        if re.shape[0] < upBound:\n",
    "            a = (upBound - re.shape[0]) // 2\n",
    "            b = upBound - re.shape[0] - a\n",
    "            a = torch.zeros((a, re.shape[1]))\n",
    "            b = torch.zeros((b, re.shape[1]))\n",
    "            return torch.cat([a, re, b], dim=0).unsqueeze(0)\n",
    "        elif re.shape[0] == upBound:\n",
    "            return re.unsqueeze(0)\n",
    "        else:\n",
    "            return re[:upBound, :].unsqueeze(0)\n",
    "        \n",
    "    def KFolder(self, K=10, shuffle=True):\n",
    "            KF = KFold(n_splits=K, shuffle=shuffle)  \n",
    "            for train_index, test_index in KF.split(self.X):\n",
    "                yield train_index, test_index\n",
    "    \n",
    "    def DataIter(self, batchsize, data_index):\n",
    "        '''输入K折交叉验证给出来的index'''\n",
    "        \n",
    "        for i in range(0, data_index.shape[0], batchsize):\n",
    "            upper = min(i + batchsize, data_index.shape[0])\n",
    "            x_l = []\n",
    "            y_l = []\n",
    "            for j in range(i, upper):\n",
    "                x_l.append(self.X[j].unsqueeze(0))\n",
    "                y_l.append(self.y[j])\n",
    "            yield torch.cat(x_l, dim=0), torch.LongTensor(y_l)\n",
    "\n",
    "test = myDataset()\n",
    "\n",
    "for train, valid in test.KFolder():\n",
    "    for x, y in test.DataIter(7, train):\n",
    "        print(x.shape)\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataset, train_idx, valid_idx, batch_size, num_epochs, lr, device, verbose=0):\n",
    "    # 初始化参数\n",
    "    def init_weight(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weight)\n",
    "    if verbose != 0:\n",
    "        print(f'training on: {device}')\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam([p for p in net.parameters() if p.requires_grad==True], lr=lr)\n",
    "    loss = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    #res = [] # 训练集梯度，训练集正确率，训练集总数\n",
    "    recorder = Accumulator(3)\n",
    "    validRecorder = Accumulator(3)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "         # 训练集梯度，训练集正确率，训练集总数\n",
    "        net.train()\n",
    "        for X, y in dataset.DataIter(batch_size, train_idx):\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            yhat = net(X)\n",
    "            #print(yhat.shape) \n",
    "            #print(y.shape)\n",
    "            l = loss(yhat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            correct = (yhat.argmax(axis=1) == y).sum()\n",
    "            acc = int(correct) / int(y.shape[0])\n",
    "\n",
    "            recorder.add(float(l * X.shape[0]), correct, X.shape[0]) #说明lossfun里，梯度除以了bachsize\n",
    "\n",
    "        # 正确率和平均损失\n",
    "        net.eval()\n",
    "        for X, y in dataset.DataIter(batch_size, valid_idx):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            yhat = net(X)\n",
    "            #print(yhat)\n",
    "            l = loss(yhat, y)\n",
    "            correct = (yhat.argmax(axis=1) == y).sum()\n",
    "            acc = int(correct) / int(y.shape[0])\n",
    "            validRecorder.add(float(l * X.shape[0]), correct, X.shape[0]) #说明lossfun里，梯度除以了bachsize\n",
    "\n",
    "        if verbose != 0:\n",
    "            print(f'epoch = {epoch+1}')\n",
    "            #print(recorder[1], recorder[2], recorder[0])\n",
    "            print(f'训练集正确率：{recorder[1]/recorder[2]:.3f}，训练集平均loss {recorder[0]:.3f}.', end=' ')\n",
    "            print(f'验证集正确率：{validRecorder[1]/validRecorder[2]:.3f}，验证集平均loss {validRecorder[0]:.3f}.')\n",
    "        recorder.clear()\n",
    "        validRecorder.clear()\n",
    "\n",
    "    return recorder, validRecorder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d: torch.Size([40, 1, 10, 49])\n",
      "ReLU: torch.Size([40, 1, 10, 49])\n",
      "MaxPool2d: torch.Size([40, 1, 5, 24])\n",
      "Conv2d: torch.Size([40, 1, 3, 10])\n",
      "Flatten: torch.Size([40, 30])\n",
      "Linear: torch.Size([40, 12])\n",
      "ReLU: torch.Size([40, 12])\n",
      "Dropout: torch.Size([40, 12])\n",
      "Linear: torch.Size([40, 3])\n"
     ]
    }
   ],
   "source": [
    "# 定义网络\n",
    "\n",
    "def get_net(isPCA):\n",
    "    if isPCA: # 输入变成了[1, 30, 30]\n",
    "        # 发现不PCA的已经很可以了，遂不写这部分了\n",
    "        return torch.nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, padding=(0, 0), stride=3), # [1, 30, 30] -> [2, 12, 44]\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),   # [1, 12, 44] -> [1, 6, 22]\n",
    "        nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=2),   # [1, 6, 22] -> [1, 2, 10]\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(20, 12)\n",
    "        , nn.ReLU(), nn.Dropout(p=0.5),\n",
    "        nn.Linear(12, 3)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # 输入变成了[1, 30, 151]\n",
    "        return torch.nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 7), padding=(0, 0), stride=3), # [1, 30, 151] -> [1, 10, 49]\n",
    "        nn.ReLU(), #nn.Dropout(p=0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),   # [1, 10, 49] -> [1, 5, 24]\n",
    "        nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 6), stride=(1, 2)),   # [1, 5, 24] -> [1, 3, 10]\n",
    "        nn.Flatten(), #nn.Dropout(p=0.5),\n",
    "        nn.Linear(30, 12),\n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(12, 3)\n",
    "        )\n",
    "\n",
    "x = torch.rand((40, 1, 30, 151))\n",
    "model = get_net(0)\n",
    "for layer in model.children():\n",
    "    x = layer(x)\n",
    "    print(f\"{layer.__class__.__name__}: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k折交叉验证: 100%|██████████| 10/10 [00:45<00:00,  4.57s/次]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集acc: mean = 0.728, std = 0.094\n",
      "验证集acc: mean = 0.844, std = 0.136\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "ISPCA = False\n",
    "dataset = myDataset()\n",
    "# 训练超参数\n",
    "lr = 0.01\n",
    "num_epoch = 15\n",
    "batch_size = 5\n",
    "exp_stats_train = []\n",
    "exp_stats_valid = []\n",
    "EXPERIMENT = 5\n",
    "K = 10\n",
    "pybar = tqdm(total=EXPERIMENT*K, desc='k折交叉验证', unit='次')\n",
    "\n",
    "for exp in range(EXPERIMENT):\n",
    "    for train_idx, valid_idx in dataset.KFolder(K=K):\n",
    "        # 正式训练\n",
    "        pybar.update(1)\n",
    "        net = get_net(False)\n",
    "        train_rec, valid_rec = train(net, dataset, train_idx,\n",
    "                        valid_idx,\n",
    "                        batch_size, num_epoch, lr, device='cpu', verbose=0)\n",
    "        # 取出验证集最后一个epoch的正确率\n",
    "        #print(train_rec.read_backup(1))\n",
    "        exp_stats_train.append(train_rec.read_backup(1)[-1]/train_rec.read_backup(2)[-1])  \n",
    "        exp_stats_valid.append(valid_rec.read_backup(1)[-1]/valid_rec.read_backup(2)[-1])\n",
    "\n",
    "exp_stats_train = np.array(exp_stats_train)\n",
    "exp_stats_valid = np.array(exp_stats_valid)\n",
    "\n",
    "print(f'训练集acc: mean = {exp_stats_train.mean():.3f}, std = {exp_stats_train.std():.3f}')\n",
    "print(f'估计泛化误差：验证集acc: mean = {exp_stats_valid.mean():.3f}, std = {exp_stats_valid.std():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
