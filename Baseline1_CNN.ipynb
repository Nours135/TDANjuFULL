{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先从简单的CNN开始写吧，嘶，主要是数据太少了orzzzzz\n",
    "# 所以只能做分类了，完蛋，我开始写之前怎么就没想到这点呢\n",
    "# 没事，3个类，33个数据一类，勉勉强强够了，大不了我自己再洗一年的数据\n",
    "\n",
    "import pandas as pd\n",
    "from utils import randomSplit, Accumulator\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler  # 归一化\n",
    "\n",
    "\n",
    "def rank2class(df):\n",
    "    if df['LgRk'] <= 6:\n",
    "        return 0\n",
    "    elif 6 < df['LgRk'] <= 13:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset():\n",
    "    def __init__(self):\n",
    "        self.player = pd.read_csv('datacleaning/modified_data.csv', header=0, encoding='unicode_escape', delimiter=';')\n",
    "        self.player = self.player.drop(['Rk', 'Player', 'Nation', 'Pos', 'Comp', 'Age', 'Born'], axis=1)\n",
    "        scaler = StandardScaler()  # z score 归一化\n",
    "        for col in self.player.columns:\n",
    "            if col == 'Squad': continue\n",
    "            self.player[[col]] = scaler.fit_transform(self.player[[col]])\n",
    "\n",
    "\n",
    "        self.league = pd.read_excel('datacleaning/Big 5 European Leagues.xlsx', sheet_name='Big 5 European Leagues Stats')\n",
    "        self.league['tier'] = self.league.apply(rank2class, axis=1)\n",
    "        self.league = self.league[['Squad', 'tier']].values             \n",
    "        # 划分集合\n",
    "        self.trainSet, self.validSet, self.testSet = randomSplit(self.league, part=(0.65, 1.0, 1.0))\n",
    "        self.dataSource = dict()\n",
    "        self.dataSource['train'] = self.trainSet\n",
    "        self.dataSource['valid'] = self.validSet\n",
    "        self.dataSource['test'] = self.testSet\n",
    "\n",
    "\n",
    "    def Squad2Player(self, squad):\n",
    "        \"输入squad的名字，输出球队球员的数据\"\n",
    "        re = self.player[self.player['Squad'] == squad].drop('Squad', axis=1)\n",
    "        re = torch.Tensor(re.values)\n",
    "\n",
    "        # 下面是reshape，在这里就做了吧\n",
    "        # return shape [1, 40, 135]\n",
    "        if re.shape[0] < 40:\n",
    "            a = (40 - re.shape[0]) // 2\n",
    "            b = 40 - re.shape[0] - a\n",
    "            a = torch.zeros((a, re.shape[1]))\n",
    "            b = torch.zeros((b, re.shape[1]))\n",
    "            return torch.cat([a, re, b], dim=0).unsqueeze(0)\n",
    "        elif re.shape[0] == 40:\n",
    "            return re.unsqueeze(0)\n",
    "        else:\n",
    "            return re[:40, :].unsqueeze(0)\n",
    "        \n",
    "\n",
    "    \n",
    "    def DataIter(self, batchsize, source, shuffle=True):\n",
    "        assert source in ('train', 'valid', 'test')\n",
    "        data = self.dataSource[source]\n",
    "        if shuffle:\n",
    "            np.random.shuffle(data)\n",
    "        for i in range(0, data.shape[0], batchsize):\n",
    "            upper = min(i + batchsize, data.shape[0] - 1)\n",
    "            x_l = []\n",
    "            y_l = []\n",
    "            for j in range(i, upper):\n",
    "                x_l.append(self.Squad2Player(data[j, 0]).unsqueeze(0))\n",
    "                y_l.append(data[j, 1])\n",
    "            yield torch.cat(x_l, dim=0), torch.LongTensor(y_l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataset, batch_size, num_epochs, lr, device):\n",
    "    # 初始化参数\n",
    "    def init_weight(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weight)\n",
    "    \n",
    "    print(f'training on: {device}')\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam([p for p in net.parameters() if p.requires_grad==True], lr=lr)\n",
    "    loss = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    res = [] # 训练集梯度，训练集正确率，训练集总数\n",
    "    for epoch in range(num_epochs):\n",
    "        recorder = Accumulator(3) # 训练集梯度，训练集正确率，训练集总数\n",
    "        net.train()\n",
    "        for X, y in dataset.DataIter(batch_size, 'train'):\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            yhat = net(X)\n",
    "            l = loss(yhat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            correct = (yhat.argmax(axis=1) == y).sum()\n",
    "            acc = int(correct) / int(y.shape[0])\n",
    "\n",
    "            recorder.add(float(l * X.shape[0]), correct, X.shape[0]) #说明lossfun里，梯度除以了bachsize\n",
    "\n",
    "        # 正确率和平均损失\n",
    "        net.eval()\n",
    "        validRecorder = Accumulator(3)\n",
    "        for X, y in dataset.DataIter(batch_size, 'valid'):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            yhat = net(X)\n",
    "            l = loss(yhat, y)\n",
    "            correct = (yhat.argmax(axis=1) == y).sum()\n",
    "            acc = int(correct) / int(y.shape[0])\n",
    "            validRecorder.add(float(l * X.shape[0]), correct, X.shape[0]) #说明lossfun里，梯度除以了bachsize\n",
    "\n",
    "\n",
    "        print(f'epoch = {epoch+1}')\n",
    "        print(f'训练集正确率：{recorder[1]/recorder[2]:.3f}，训练集平均loss {recorder[0]/recorder[2]:.3f}.', end=' ')\n",
    "        print(f'验证集正确率：{validRecorder[1]/validRecorder[2]:.3f}，验证集平均loss {validRecorder[0]/validRecorder[2]:.3f}.')\n",
    "        \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 12])\n"
     ]
    }
   ],
   "source": [
    "# 定义网络\n",
    "CNNclassifier = torch.nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=1, kernel_size=7, padding=(0, 1), stride=3), # [1, 40, 135] -> [1, 12, 44]\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),   # [1, 12, 44] -> [1, 6, 22]\n",
    "    nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=2),   # [1, 6, 22] -> [1, 2, 10]\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(20, 12)\n",
    "    #, nn.ReLU(), nn.Dropout(p=0.5),\n",
    "    #nn.Linear(12, 3)\n",
    "    )\n",
    "\n",
    "x = torch.rand((40, 1, 40, 135))\n",
    "print(CNNclassifier(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on: cpu\n",
      "epoch = 1\n",
      "训练集正确率：0.339，训练集平均loss 1.902. 验证集正确率：0.294，验证集平均loss 2.082.\n",
      "epoch = 2\n",
      "训练集正确率：0.613，训练集平均loss 1.416. 验证集正确率：0.294，验证集平均loss 1.704.\n",
      "epoch = 3\n",
      "训练集正确率：0.726，训练集平均loss 1.226. 验证集正确率：0.441，验证集平均loss 1.545.\n",
      "epoch = 4\n",
      "训练集正确率：0.726，训练集平均loss 1.132. 验证集正确率：0.559，验证集平均loss 1.524.\n",
      "epoch = 5\n",
      "训练集正确率：0.855，训练集平均loss 0.993. 验证集正确率：0.559，验证集平均loss 1.560.\n",
      "epoch = 6\n",
      "训练集正确率：0.806，训练集平均loss 0.946. 验证集正确率：0.529，验证集平均loss 1.688.\n",
      "epoch = 7\n",
      "训练集正确率：0.903，训练集平均loss 0.849. 验证集正确率：0.500，验证集平均loss 1.841.\n",
      "epoch = 8\n",
      "训练集正确率：0.935，训练集平均loss 0.757. 验证集正确率：0.618，验证集平均loss 1.883.\n",
      "epoch = 9\n",
      "训练集正确率：0.935，训练集平均loss 0.737. 验证集正确率：0.559，验证集平均loss 2.081.\n",
      "epoch = 10\n",
      "训练集正确率：0.968，训练集平均loss 0.722. 验证集正确率：0.529，验证集平均loss 2.158.\n"
     ]
    }
   ],
   "source": [
    "dataset = myDataset()\n",
    "# 训练超参数\n",
    "lr = 0.05\n",
    "num_epoch = 10\n",
    "batch_size = 5\n",
    "# 正式训练\n",
    "data_l = train(CNNclassifier, dataset, batch_size, num_epoch, lr, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
